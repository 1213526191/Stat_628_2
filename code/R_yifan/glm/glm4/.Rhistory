pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
tidy_train4 = read_csv("/Users/Lyf/Desktop/tidy_train_tfidf_n100.csv")
tidy_test4 = read_csv("/Users/Lyf/Desktop/tidy_test_tfidf_n100.csv")
tidy_train3 = read_csv("/Users/Lyf/Desktop/tidy_train_tfidf_n100.csv")
tidy_test3 = read_csv("/Users/Lyf/Desktop/tidy_test_tfidf_n100.csv")
tidy_all <- bind_rows(tidy_test3, tidy_train3)
t2 = Sys.time()
all_matrix <- tidy_all %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
starss = c(rep(0, n1), train$stars)
n2 = dim(all_matrix)[2]
all_matrix2 = cbind(all_matrix, starss)
test_ori = read_csv("/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/test2.csv")
test = data_frame(line = test_ori$Id,
text = test_ori$text,
stars = 0)
n1 = nrow(test)
n1
n1 = 1016664
starss = c(rep(0, n1), train$stars)
train_ori = read_csv("../../data/random100000w.csv")
train = data_frame(line = 1:nrow(train_ori),
text = train_ori$text,
stars = train_ori$stars)
starss = c(rep(0, n1), train$stars)
n2 = dim(all_matrix)[2]
all_matrix2 = cbind(all_matrix, starss)
test_index = c(1:n1)
train_matrix = all_matrix2[-test_index,]
test_matrix = all_matrix2[test_index,]
fit = glmnet(train_matrix[,1:n2], train_matrix[,n2+1])
cv <- cv.glmnet(train_matrix[,1:n2], train_matrix[,n2+1], nfolds=5)
pred <- predict(fit, test_matrix[, 1:n2], type="response", s=cv$lambda.min)
my_sh
my_sh = c(1.314392, 3.028014, 3.541586, 4.148861)
pred_new = mypred(my_sh, pred)
result = tibble(Id = c(1:length(pred_new)),
Prediction1 = pred_new)
write_csv(result, "/Users/Lyf/Desktop/result.csv")
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data_ori = read_csv("../../data/li_train_all.csv")
dim(data_ori)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data2 = as.numeric(data[2:6])
myvar = function(data, counts){
data2 = as.numeric(data[2:6])
for(i in 1:5){
data2[i] = data2[i]/counts[i]
}
data2 = data2/sum(data2)
return(var(data2))
}
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mypred = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
test_ori = read_csv("/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/test2.csv")
test = data_frame(line = test_ori$Id,
text = test_ori$text,
stars = 0)
n1 = nrow(test)
features = read_csv("../../data/feature3_all.csv")
major <- features %>%
select(word)
t2 = Sys.time()
tidy_test <- test %>%
unnest_tokens(word, text)
t3 = Sys.time()
print(t3-t2)
train_ori = read_csv("/Users/Lyf/Desktop/train_en3.csv")
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
tidy_test2
t2 = Sys.time()
tidy_test3 <- tidy_test2 %>%
distinct(line, stars, word)
t3 = Sys.time()
print(t3-t2)
tidy_train4 = read_csv("/Users/Lyf/Desktop/train_all3.csv")
train
train = data_frame(line = 1:nrow(train_ori),
text = train_ori$text,
stars = train_ori$stars)
tidy_train3
tidy_train4
tidy_train3 = tidy_train4
tidy_train3
xx <- tidy_train3 %>%
group_by(line) %>%
summarise(kkk = 0)
w = which(!train$line   %in% xx$line)
w
star_mode = round(mean(train$stars))
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w))
)
my_tidy
tidy_train4 <- bind_rows(tidy_train3, my_tidy) %>%
arrange(line) %>%
mutate(count = 1)
tidy_train4
max(tidy_train4$line)
tidy_train4$line = tidy_train4$line + n1
tidy_test4
tidy_test3
# write_csv(tidy_train4, "/Users/Lyf/Desktop/tidy_train3.csv")
write_csv(tidy_train4, "/Users/Lyf/Desktop/train_all3.csv")
xx <- tidy_test3 %>%
group_by(line) %>%
summarise(kkk = 0)
w = which(!test$line   %in% xx$line)
w
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w))
)
t2 = Sys.time()
tidy_test4 <- bind_rows(tidy_test3, my_tidy) %>%
arrange(line) %>%
mutate(count = 1)
t3 = Sys.time()
print(t3-t2)
write_csv(tidy_test4, "/Users/Lyf/Desktop/tidy_test3.csv")
test_ori = read_csv("/Users/Lyf/Desktop/test_en3.csv")
dim(test_ori)
test = data_frame(line = test_ori$Id,
text = test_ori$text,
stars = 0)
n1 = nrow(test)
t2 = Sys.time()
tidy_test <- test %>%
unnest_tokens(word, text)
t3 = Sys.time()
print(t3-t2)
t3-t2
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
t2 = Sys.time()
tidy_test3 <- tidy_test2 %>%
distinct(line, stars, word)
t3 = Sys.time()
print(t3-t2)
xx <- tidy_test3 %>%
group_by(line) %>%
summarise(kkk = 0)
w = which(!test$line   %in% xx$line)
w
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w))
)
tidy_train4
t2 = Sys.time()
tidy_test4 <- bind_rows(tidy_test3, my_tidy) %>%
arrange(line) %>%
mutate(count = 1)
t3 = Sys.time()
print(t3-t2)
# write_csv(tidy_test4, "/Users/Lyf/Desktop/tidy_test3.csv")
write_csv(tidy_test4, "/Users/Lyf/Desktop/test_all3.csv")
tidy_all <- bind_rows(tidy_test4, tidy_train4)
tidy_train4
t2 = Sys.time()
all_matrix <- tidy_all %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
n1
train
# train_ori = read_csv("../../data/random100000w.csv")
starss = c(rep(0, n1), train$stars)
n2 = dim(all_matrix)[2]
all_matrix2 = cbind(all_matrix, starss)
test_index = c(1:n1)
train_matrix = all_matrix2[-test_index,]
test_matrix = all_matrix2[test_index,]
train_matrix[,n2+1]
min(train_matrix[,n2+1])
fit = glmnet(train_matrix[,1:n2], train_matrix[,n2+1])
fit
Sys.time()
t1 = Sys.time()
cv <- cv.glmnet(train_matrix[,1:n2], train_matrix[,n2+1], nfolds=5)
t2 = Sys.time()
print(t2-t1)
cv
cv$lambda.min
write_csv(cv, "/Users/Lyf/Desktop/cv.csv")
write_csv(cv$lambda.min, "/Users/Lyf/Desktop/cv.csv")
cv$lambda.min
as.data.frame(cv$lambda.min)
write_csv(as.data.frame(cv$lambda.min), "/Users/Lyf/Desktop/cv.csv")
write_csv(as.data.frame(cv), "/Users/Lyf/Desktop/cv2.csv")
?save
save(fit)
save(fit, "/Users/Lyf/Desktop/fit.RData")
save(fit, file = "/Users/Lyf/Desktop/fit.RData")
save(cv, file = "/Users/Lyf/Desktop/cv.RData")
t1 = Sys.time()
pred <- predict(fit, test_matrix[, 1:n2], type="response", s=cv$lambda.min)
t2 = Sys.time()
print(t2-t1)
my_sh = c(1.473933, 2.924439, 3.485770, 4.247829)
pred_new = mypred(my_sh, pred)
result = tibble(Id = c(1:length(pred_new)),
Prediction1 = pred_new)
write_csv(result, "/Users/Lyf/Desktop/result3_all.csv")
dim(result)
library(neuralnet)
install.packages("neuralnet")
library(neuralnet)
?neuralnet
setwd("/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/glm/glm4")
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data_ori = read_csv("../../data/random100000w.csv")
data_ori = read_csv("/Users/Lyf/Github/Stat_628_2/data/random100000w.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
n1 = length(data_df$line)
my_sh = c(1.5, 2.5, 3.5 ,4.5)
var_sh = 0.001
n_sh = 100
myvar = function(data, counts){
data2 = as.numeric(data[2:6])
for(i in 1:5){
data2[i] = data2[i]/counts[i]
}
data2 = data2/sum(data2)
return(var(data2))
}
myexp = function(data, counts){
data2 = as.numeric(data[2:6])
for(i in 1:5){
data2[i] = data2[i]/counts[i]
}
data2 = data2/sum(data2)
return(sum(data2*c(1,2,3,4,5)))
}
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mypred = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
tidy_all <- data_df %>%
unnest_tokens(word, text)
count <- tidy_all %>%
count(stars)
tidy_all
tidy_all2 <- tidy_all %>%
distinct(line, stars, word)
major <- tidy_all2 %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count))
major
major <- tidy_all2 %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
filter(count > n_sh)
n_sh
tidy_all3 <- tidy_all3 %>%
inner_join(major, by = "word")
tidy_all3 <- tidy_all2 %>%
inner_join(major, by = "word")
tidy_all_count <- tidy_all3 %>%
group_by(stars) %>%
summarise(n = n())
tidy_all_count
tidy_var = tidy_all3 %>%
group_by(word, stars) %>%
summarise(count = n()) %>%
spread(stars, count, fill = 0)
tidy_var
myexp()
myexp(
)
myexp
myvar_test = apply(tidy_var, 1, myvar, counts = tidy_all_count$n)
myexpect_test = apply(tidy_var, 1, myexp, counts = tidy_all_count$n)
myvar_test
myexp_test = apply(tidy_var, 1, myexp, counts = tidy_all_count$n)
word_var <- data_frame(word = tidy_var$word,
var = myvar_test,
exp = myexp_test) %>%
arrange(desc(var))
word_var
var_sh = 0.001
k = sum(word_var$var>var_sh)
k
var_sh = 0.01
k = sum(word_var$var>var_sh)
k
cv_n = 5
cv_df = tibble(index = c(1:cv_n))
set.seed(615)
cv_index = sample_n(cv_df, nrow(data_df), replace = T)
iii=1
ii
ii=1
split <- which(cv_index$index != ii)
train <- data_df[split,]
test <- data_df[-split,]
tidy_train <- train %>%
unnest_tokens(word, text)
tidy_train <- train %>%
unnest_tokens(word, text) %>%
distinct(line, stars, word)
tidy_test <- test %>%
unnest_tokens(word, text) %>%
distinct(line, stars, word)
major <- tidy_train %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
filter(count > n_sh)
tidy_train3 <- tidy_train %>%
inner_join(major, by = "word")
tidy_all_count <- tidy_train3 %>%
group_by(stars) %>%
summarise(n = n())
tidy_train_count <- tidy_train3 %>%
group_by(stars) %>%
summarise(n = n())
tidy_var = tidy_train3 %>%
group_by(word, stars) %>%
summarise(count = n()) %>%
spread(stars, count, fill = 0)
myvar_test = apply(tidy_var, 1, myvar, counts = tidy_train_count$n)
myexp_test = apply(tidy_var, 1, myexp, counts = tidy_train_count$n)
word_var <- data_frame(word = tidy_var$word,
var = myvar_test,
exp = myexp_test) %>%
arrange(desc(var))
var_sh = 0.01
k = sum(word_var$var>var_sh)
k
# var_sh = 0.01
# k = sum(word_var$var>var_sh)
major <- word_var %>%
filter(var>var_sh) %>%
arrange(desc(exp))
major
tidy_test
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word")
tidy_test2
data_df[7,]
data_df[21,]
var_sh = 0.001
# var_sh = 0.01
# k = sum(word_var$var>var_sh)
major_word <- word_var %>%
filter(var>var_sh) %>%
arrange(desc(exp))
tidy_test2 <- tidy_test %>%
inner_join(major_word, by = "word")
tidy_test2
test
pred1 <- tidy_test2 %>%
group_by(line) %>%
summarise(pred = mean(exp))
pred1
,max(pred1)
max(pred1)
max(pred1$pred)
min(pred1$pred)
pred1 <- tidy_test2 %>%
group_by(line) %>%
summarise(pred = mean(exp), count = n())
pred1
w = which(!test$line %in% pred1$line)
w
var_sh = 0.005
# var_sh = 0.01
# k = sum(word_var$var>var_sh)
major_word <- word_var %>%
filter(var>var_sh) %>%
arrange(desc(exp))
tidy_test2 <- tidy_test %>%
inner_join(major_word, by = "word")
pred1 <- tidy_test2 %>%
group_by(line) %>%
summarise(pred = mean(exp), count = n())
w = which(!test$line %in% pred1$line)
w
pred1
star_mode = Mode(train$stars)
pred2 <- data_frame(line = w, pred = star_mode, count = 0)
pred2
Mode(train$stars)
pred <- bind_rows(pred1, pred2) %>%
arrange(line)
pred
pred
mypred = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
mymse = function(sh, pred_ori, true_value){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(sum((pred_new- true_value)^2))
}
my_sh = optim(c(1.5,2.5,3.5,4.5),mymse, pred_ori = pred, true_value = test$stars)
my_sh
pred
pred$pred
test$stars
my_sh = optim(c(1.5,2.5,3.5,4.5),mymse, pred_ori = pred$pred, true_value = test$stars)
my_sh
mymse = function(sh, pred_ori, true_value){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(sum((pred_new- true_value)^2))
}
my_sh = optim(c(1.5,2.5,3.5,4.5),mymse, pred_ori = pred$pred, true_value = test$stars)
my_sh
var_sh = 0.001
# var_sh = 0.01
# k = sum(word_var$var>var_sh)
major_word <- word_var %>%
filter(var>var_sh) %>%
arrange(desc(exp))
tidy_test2 <- tidy_test %>%
inner_join(major_word, by = "word")
pred1 <- tidy_test2 %>%
group_by(line) %>%
summarise(pred = mean(exp), count = n())
w = which(!test$line %in% pred1$line)
w
star_mode = Mode(train$stars)
pred2 <- data_frame(line = w, pred = star_mode, count = 0)
pred <- bind_rows(pred1, pred2) %>%
arrange(line)
mymse = function(sh, pred_ori, true_value){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(sum((pred_new- true_value)^2))
}
my_sh = optim(c(1.5,2.5,3.5,4.5),mymse, pred_ori = pred$pred, true_value = test$stars)
my_sh
17810/nrow(test)
nrow(test)
