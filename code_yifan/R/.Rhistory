ii=7
iii=7
print(iii)
var_sh = var_sh_all[iii]
var_sh
n_sh = 0.01*n1
var_sh_all = 0.002
NN = length(var_sh_all)
mse4var = numeric(NN)
NN
iii=1
print(iii)
var_sh = var_sh_all[iii]
pred_ori = numeric(nrow(cv_index))
ii=1
split <- which(cv_index$index != ii)
train <- data_df[split,]
test <- data_df[-split,]
tidy_train <- train %>%
unnest_tokens(word, text)
tidy_test <- test %>%
unnest_tokens(word, text)
data("stop_words")
data_not <- data_df %>%
unnest_tokens(word, text)
var_not = data_frame(word = stop_words$word, var = 0)
count <- data_not %>%
count(stars)
for(i in 1:nrow(stop_words)){
var_not$var[i] = myvar(data_not, stop_words$word[i], count$n)
}
index_not = which(var_not$var>var_sh)
my_stop = stop_words[-index_not,]
my_stop2 <- my_stop
my_stop2$word = apply(my_stop, 1, add_not)
tidy_train <- tidy_train %>%
anti_join(my_stop, by = "word") %>%
anti_join(my_stop2, by = "word")
major <- tidy_train %>%
count(word, sort = T) %>%
filter(n > n_sh)
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
major
tidy_train
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
tidy_train_count <- tidy_train %>%
count(stars)
for(i in 1:nrow(word_var)){
word_var$var[i] = myvar(tidy_train, word_var$word[i], tidy_train_count$nn)
}
word_var <- word_var %>%
arrange(desc(var))
word_var
# for(i in 1:10){
#   this_word = word_var$word[i]
#   x <- tidy_test %>%
#     filter(word == this_word) %>%
#     count(stars) %>%
#     mutate(xx = n/sum(n))
#   ggplot(data = x) +
#     geom_bar(aes(x = stars, y = xx), stat = 'identity') +
#     ggtitle(this_word)
# }
k = sum(word_var$var>var_sh)
k
tidy_all <- data_df %>%
unnest_tokens(word, text)
tidy_all2 <- tidy_all %>%
filter(tidy_all$word %in% word_var$word[1:k]) %>%
mutate(count = 1)
xx <- tidy_all2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!c(1:nrow(data_df))   %in% xx$line)
star_mode = Mode(train$stars)
star_mod
star_mode
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
tidy_all3 <- full_join(tidy_all2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
n2 = length(unique(tidy_all3$word))
all_sp <- tidy_all3 %>%
cast_dtm(line, word, count)
all_matrix = dtm.to.Matrix(all_sp)
all_matrix2 = cbind(all_matrix, data_df$stars)
split2 = split
train2 <- all_matrix2[split2,]
test2 <- all_matrix2[-split2,]
true_value = data_df$stars[-split2]
fit = glmnet(train2[,1:n2], train2[,n2+1])
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5)
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred
pred_new = mymse2(my_sh, pred)
pred_new = mymse2(my_sh, pred_ori)
pred_new
pred
my_sh
sum((pred-true_value)^2)
?cv.glmnet
?glmnet
fit = glmnet(train2[,1:n2], train2[,n2+1], family = "multinomial")
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5,family = "multinomial")
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred
dim(pred)
apply(pred,1,max)
apply(pred,1,which.max)
pred2 = apply(pred,1,which.max)
sum((pred2-true_value)^2)
fit = glmnet(train2[,1:n2], train2[,n2+1])
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5)
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred
pred_new = mymse2(my_sh, pred)
pred_new
sum((pred_new-true_value)^2)
data_ori = read_csv("../../data/li_first100000forR.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
n1 = length(data_df$line)
my_sh = c(1.45, 2.92, 3.6, 4.15)
n1
my_sh = c(1.45, 2.92, 3.6, 4.15)
cv_n = 5
cv_df = tibble(index = c(1:cv_n))
set.seed(615)
cv_index = sample_n(cv_df, nrow(data_df), replace = T)
myvar = function(data, thisword, counts){
data_useful <- data %>%
filter(word == thisword) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mymse2 = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
dtm.to.Matrix <- function(dtm)
{
m <- Matrix(0, nrow = dtm$nrow, ncol = dtm$ncol, sparse = TRUE)
for (index in 1:length(dtm$i)){
m[dtm$i[index], dtm$j[index]] <- dtm$v[index]
}
return(m)
}
n_sh = 0.01*n1
var_sh_all = 0.01
NN = length(var_sh_all)
mse4var = numeric(NN)
NN
iii=1
print(iii)
var_sh = var_sh_all[iii]
pred_ori = numeric(nrow(cv_index))
ii=1
split <- which(cv_index$index != ii)
train <- data_df[split,]
test <- data_df[-split,]
tidy_train <- train %>%
unnest_tokens(word, text)
tidy_test <- test %>%
unnest_tokens(word, text)
data("stop_words")
data_not <- data_df %>%
unnest_tokens(word, text)
stop_words
count
var = apply(data_not, 1, myvar, words = stop_words, counts =count$n )
data = data_not
words = stop_words[1:5,]
counts = count$n
data
words
data_useful <- data %>%
filter(word == words$word) %>%
count(stars)
data_useful <- data %>%
filter(word == words$word[1]) %>%
count(stars)
data_useful
var = apply(words, 1, myvae, data = data, counts = counts)
var = apply(words, 1, myvar, data = data, counts = counts)
myvar = function(words, data, counts){
data_useful <- data %>%
filter(word == words$word) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
var = apply(words, 1, myvar, data = data, counts = counts)
data_useful
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
data_useful2
var(data_useful2$xx)
words = stop_words[1,]
myvar(words, data, counts)
words = stop_words[1:2,]
?apply
apply(words, 2, myvar, data = data_not, counts = count$n)
apply(words, 1, myvar, data = data_not, counts = count$n)
myvar = function(words, data, counts){
data_useful <- data %>%
filter(word == words) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
apply(words$word, 1, myvar, data = data_not, counts = count$n)
apply(t(words$word), 1, myvar, data = data_not, counts = count$n)
apply(words$word, 2, myvar, data = data_not, counts = count$n)
dim(stop_words)
dim(stop_words[,1])
apply(words$word[,1], 1, myvar, data = data_not, counts = count$n)
words$word
apply(words[,1], 1, myvar, data = data_not, counts = count$n)
myvar = function(words, data, counts){
data_useful <- data %>%
filter(word == words) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
stop_words
var_ls = apply(stop_words[1:5,1], 1, myvar, data = data_not, counts = count$n)
var_ls
var_ls = apply(stop_words[,1], 1, myvar, data = data_not, counts = count$n)
var_not
var_not$var
var_not = data_frame(word = stop_words$word, var = 0)
count <- data_not %>%
count(stars)
var_not$var = apply(stop_words[,1], 1, myvar, data = data_not, counts = count$n)
var_not
index_not = which(var_not$var>var_sh)
length(index_not)
index_not = which(var_not$var>var_sh)
my_stop = stop_words[-index_not,]
my_stop2 <- my_stop
my_stop2$word = apply(my_stop, 1, add_not)
tidy_train <- tidy_train %>%
anti_join(my_stop, by = "word") %>%
anti_join(my_stop2, by = "word")
major <- tidy_train %>%
count(word, sort = T) %>%
filter(n > n_sh)
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
tidy_train_count <- tidy_train %>%
count(stars)
major
var_not$var = apply(word_var[,1], 1, myvar,
data = tidy_train, counts = tidy_train_count$nn)
word_var[,1]
tidy_train
tidy_train_count$nn
var_not
var_not$var
index_ls = which(var_not$var==0)
index_ls
var_not$word[index_ls]
word_var$var <- apply(word_var[,1], 1, myvar,
data = tidy_train, counts = tidy_train_count$nn)
word_var <- word_var %>%
arrange(desc(var))
word_var
# for(i in 1:10){
#   this_word = word_var$word[i]
#   x <- tidy_test %>%
#     filter(word == this_word) %>%
#     count(stars) %>%
#     mutate(xx = n/sum(n))
#   ggplot(data = x) +
#     geom_bar(aes(x = stars, y = xx), stat = 'identity') +
#     ggtitle(this_word)
# }
k = sum(word_var$var>var_sh)
k
var_sh
tidy_all <- data_df %>%
unnest_tokens(word, text)
tidy_all2 <- tidy_all %>%
filter(tidy_all$word %in% word_var$word[1:k]) %>%
mutate(count = 1)
xx <- tidy_all2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!c(1:nrow(data_df))   %in% xx$line)
star_mode = Mode(train$stars)
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
tidy_all3 <- full_join(tidy_all2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
n2 = length(unique(tidy_all3$word))
all_sp <- tidy_all3 %>%
cast_dtm(line, word, count)
all_matrix = dtm.to.Matrix(all_sp)
all_matrix <- tidy_all3 %>%
cast_sparse(line, word, count)
all_matrix
all_matrix2 = cbind(all_matrix, data_df$stars)
all_matrix2
split2 = split
train2 <- all_matrix2[split2,]
test2 <- all_matrix2[-split2,]
true_value = data_df$stars[-split2]
true_value
fit = glmnet(train2[,1:n2], train2[,n2+1])
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5)
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred
sum((pred-true_value)^2)
sum((pred-true_value)^2)/length(pred)
pred_new = mymse2(my_sh, pred)
sum((pred_new-true_value)^2)/length(pred)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data_ori = read_csv("../../data/li_first100000forR.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
data_df
data_df5 <- data_df %>%
filter(stars == 5)
data_df1 <- data_df %>%
filter(stars == 1)
myvar = function(words, data, counts){
data_useful <- data %>%
filter(word == words) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
major <- data_df5 %>%
count(word, sort = T) %>%
filter(n > n_sh)
data_df5
n_sh = 0.01*nrow(data_df5)
data5 <- data_df5 %>%
unnest_tokens(word, text)
major <- data5 %>%
count(word, sort = T) %>%
filter(n > n_sh)
major
data5 <- data5 %>%
inner_join(major, by = "word")
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
data5_count <- data5 %>%
count(stars)
data5_count
n_sh = 0.01*nrow(data_df)
data_tidy <- data_df %>%
unnest_tokens(word, text)
major <- data_tidy %>%
count(word, sort = T) %>%
filter(n > n_sh)
major
data_tidy <- data_tidy %>%
inner_join(major, by = "word")
n_sh
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
data_tidy_count <- data_tidy %>%
count(stars)
data_tidy_count
word_var[,1]
word_var$var <- apply(word_var[,1], 1, myvar,
data = data_tidy, counts = data_tidy_count$nn)
word_var$var
min(word_var$var)
word_var <- word_var %>%
arrange(desc(var)) %>%
filter(var>0.01)
word_var
data_tidy
data_tidy2 <- data_tidy %>%
filter(stars == 1) %>%
filter(word %in% word_var$word) %>%
group_by(word) %>%
summarise(nnn = n())
data_tidy2
data_tidy2 <- data_tidy %>%
filter(stars == 1) %>%
filter(word %in% word_var$word) %>%
group_by(word) %>%
summarise(nnn = n()) %>%
arrange(desc(nnn))
data_tidy2
?write_csv
filename = paste("../../data/dist", n, ".csv", sep = "")
filename = paste("../../data/dist", str(n), ".csv", sep = "")
filename
filename = paste("../../data/dist", as.character(n), ".csv", sep = "")
n
n = 1
n
filename = paste("../../data/dist", str(n), ".csv", sep = "")
filename
str(n)
n = 1
filename = paste("../../data/dist", as.character(n), ".csv", sep = "")
filename
write_csv(data_tidy2, filename)
n = 5
data_tidy2 <- data_tidy %>%
filter(stars == n) %>%
filter(word %in% word_var$word) %>%
group_by(word) %>%
summarise(nnn = n()) %>%
arrange(desc(nnn))
data_tidy2
data_tidy2 <- data_tidy %>%
filter(stars == n)
data_tidy2
n = 5
data_tidy
data_tidy2 <- data_tidy %>%
filter(stars == n)
data_tidy2
data_tidy2 <- data_tidy %>%
filter(stars == 5) %>%
filter(word %in% word_var$word) %>%
group_by(word) %>%
summarise(nnn = n()) %>%
arrange(desc(nnn))
data_tidy2
filename = paste("../../data/dist", as.character(n), ".csv", sep = "")
filename
write_csv(data_tidy2, filename)
