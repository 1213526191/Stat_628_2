setwd("/Users/Lyf/Github/Stat_628_2/code_yifan/R")
tidy_train4 = read_csv("/Users/Lyf/Desktop/tidy_train_tfidf_n100.csv")
tidy_test4 = read_csv("/Users/Lyf/Desktop/tidy_test_tfidf_n100.csv")
tidy_all <- bind_rows(tidy_test4, tidy_train4)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
myvar = function(data, counts){
data2 = as.numeric(data[2:6])
for(i in 1:5){
data2[i] = data2[i]/counts[i]
}
data2 = data2/sum(data2)
return(var(data2))
}
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mypred = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
tidy_train4 = read_csv("/Users/Lyf/Desktop/tidy_train_tfidf_n100.csv")
tidy_test4 = read_csv("/Users/Lyf/Desktop/tidy_test_tfidf_n100.csv")
tidy_train3 = read_csv("/Users/Lyf/Desktop/tidy_train_tfidf_n100.csv")
tidy_test3 = read_csv("/Users/Lyf/Desktop/tidy_test_tfidf_n100.csv")
tidy_all <- bind_rows(tidy_test3, tidy_train3)
t2 = Sys.time()
all_matrix <- tidy_all %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
starss = c(rep(0, n1), train$stars)
n2 = dim(all_matrix)[2]
all_matrix2 = cbind(all_matrix, starss)
test_ori = read_csv("/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/test2.csv")
test = data_frame(line = test_ori$Id,
text = test_ori$text,
stars = 0)
n1 = nrow(test)
n1
n1 = 1016664
starss = c(rep(0, n1), train$stars)
train_ori = read_csv("../../data/random100000w.csv")
train = data_frame(line = 1:nrow(train_ori),
text = train_ori$text,
stars = train_ori$stars)
starss = c(rep(0, n1), train$stars)
n2 = dim(all_matrix)[2]
all_matrix2 = cbind(all_matrix, starss)
test_index = c(1:n1)
train_matrix = all_matrix2[-test_index,]
test_matrix = all_matrix2[test_index,]
fit = glmnet(train_matrix[,1:n2], train_matrix[,n2+1])
cv <- cv.glmnet(train_matrix[,1:n2], train_matrix[,n2+1], nfolds=5)
pred <- predict(fit, test_matrix[, 1:n2], type="response", s=cv$lambda.min)
my_sh
my_sh = c(1.314392, 3.028014, 3.541586, 4.148861)
pred_new = mypred(my_sh, pred)
result = tibble(Id = c(1:length(pred_new)),
Prediction1 = pred_new)
write_csv(result, "/Users/Lyf/Desktop/result.csv")
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data_ori = read_csv("../../data/li_train_all.csv")
dim(data_ori)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data2 = as.numeric(data[2:6])
myvar = function(data, counts){
data2 = as.numeric(data[2:6])
for(i in 1:5){
data2[i] = data2[i]/counts[i]
}
data2 = data2/sum(data2)
return(var(data2))
}
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mypred = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
test_ori = read_csv("/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/test2.csv")
test = data_frame(line = test_ori$Id,
text = test_ori$text,
stars = 0)
n1 = nrow(test)
features = read_csv("../../data/feature3_all.csv")
major <- features %>%
select(word)
t2 = Sys.time()
tidy_test <- test %>%
unnest_tokens(word, text)
t3 = Sys.time()
print(t3-t2)
train_ori = read_csv("/Users/Lyf/Desktop/train_en3.csv")
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
tidy_test2
t2 = Sys.time()
tidy_test3 <- tidy_test2 %>%
distinct(line, stars, word)
t3 = Sys.time()
print(t3-t2)
tidy_train4 = read_csv("/Users/Lyf/Desktop/train_all3.csv")
train
train = data_frame(line = 1:nrow(train_ori),
text = train_ori$text,
stars = train_ori$stars)
tidy_train3
tidy_train4
tidy_train3 = tidy_train4
tidy_train3
xx <- tidy_train3 %>%
group_by(line) %>%
summarise(kkk = 0)
w = which(!train$line   %in% xx$line)
w
star_mode = round(mean(train$stars))
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w))
)
my_tidy
tidy_train4 <- bind_rows(tidy_train3, my_tidy) %>%
arrange(line) %>%
mutate(count = 1)
tidy_train4
max(tidy_train4$line)
tidy_train4$line = tidy_train4$line + n1
tidy_test4
tidy_test3
# write_csv(tidy_train4, "/Users/Lyf/Desktop/tidy_train3.csv")
write_csv(tidy_train4, "/Users/Lyf/Desktop/train_all3.csv")
xx <- tidy_test3 %>%
group_by(line) %>%
summarise(kkk = 0)
w = which(!test$line   %in% xx$line)
w
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w))
)
t2 = Sys.time()
tidy_test4 <- bind_rows(tidy_test3, my_tidy) %>%
arrange(line) %>%
mutate(count = 1)
t3 = Sys.time()
print(t3-t2)
write_csv(tidy_test4, "/Users/Lyf/Desktop/tidy_test3.csv")
test_ori = read_csv("/Users/Lyf/Desktop/test_en3.csv")
dim(test_ori)
test = data_frame(line = test_ori$Id,
text = test_ori$text,
stars = 0)
n1 = nrow(test)
t2 = Sys.time()
tidy_test <- test %>%
unnest_tokens(word, text)
t3 = Sys.time()
print(t3-t2)
t3-t2
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
t2 = Sys.time()
tidy_test3 <- tidy_test2 %>%
distinct(line, stars, word)
t3 = Sys.time()
print(t3-t2)
xx <- tidy_test3 %>%
group_by(line) %>%
summarise(kkk = 0)
w = which(!test$line   %in% xx$line)
w
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w))
)
tidy_train4
t2 = Sys.time()
tidy_test4 <- bind_rows(tidy_test3, my_tidy) %>%
arrange(line) %>%
mutate(count = 1)
t3 = Sys.time()
print(t3-t2)
# write_csv(tidy_test4, "/Users/Lyf/Desktop/tidy_test3.csv")
write_csv(tidy_test4, "/Users/Lyf/Desktop/test_all3.csv")
tidy_all <- bind_rows(tidy_test4, tidy_train4)
tidy_train4
t2 = Sys.time()
all_matrix <- tidy_all %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
n1
train
# train_ori = read_csv("../../data/random100000w.csv")
starss = c(rep(0, n1), train$stars)
n2 = dim(all_matrix)[2]
all_matrix2 = cbind(all_matrix, starss)
test_index = c(1:n1)
train_matrix = all_matrix2[-test_index,]
test_matrix = all_matrix2[test_index,]
train_matrix[,n2+1]
min(train_matrix[,n2+1])
fit = glmnet(train_matrix[,1:n2], train_matrix[,n2+1])
fit
Sys.time()
t1 = Sys.time()
cv <- cv.glmnet(train_matrix[,1:n2], train_matrix[,n2+1], nfolds=5)
t2 = Sys.time()
print(t2-t1)
cv
cv$lambda.min
write_csv(cv, "/Users/Lyf/Desktop/cv.csv")
write_csv(cv$lambda.min, "/Users/Lyf/Desktop/cv.csv")
cv$lambda.min
as.data.frame(cv$lambda.min)
write_csv(as.data.frame(cv$lambda.min), "/Users/Lyf/Desktop/cv.csv")
write_csv(as.data.frame(cv), "/Users/Lyf/Desktop/cv2.csv")
?save
save(fit)
save(fit, "/Users/Lyf/Desktop/fit.RData")
save(fit, file = "/Users/Lyf/Desktop/fit.RData")
save(cv, file = "/Users/Lyf/Desktop/cv.RData")
t1 = Sys.time()
pred <- predict(fit, test_matrix[, 1:n2], type="response", s=cv$lambda.min)
t2 = Sys.time()
print(t2-t1)
my_sh = c(1.473933, 2.924439, 3.485770, 4.247829)
pred_new = mypred(my_sh, pred)
result = tibble(Id = c(1:length(pred_new)),
Prediction1 = pred_new)
write_csv(result, "/Users/Lyf/Desktop/result3_all.csv")
dim(result)
