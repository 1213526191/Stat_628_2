my_sh = c(1.45, 2.92, 3.6, 4.15)
# my_sh = c(1.5, 2.5, 3.5 ,4.5)
# CV ----------------------------------------------------------------------
cv_n = 5
cv_df = tibble(index = c(1:cv_n))
set.seed(615)
cv_index = sample_n(cv_df, nrow(data_df), replace = T)
# variance ----------------------------------------------------------------
myvar = function(data, thisword, counts){
data_useful <- data %>%
filter(word == thisword) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
# mode fun ----------------------------------------------------------------
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# mse ---------------------------------------------------------------------
mymse2 = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
# add not -----------------------------------------------------------------
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
# dtm2matrix --------------------------------------------------------------
dtm.to.Matrix <- function(dtm)
{
m <- Matrix(0, nrow = dtm$nrow, ncol = dtm$ncol, sparse = TRUE)
for (index in 1:length(dtm$i)){
m[dtm$i[index], dtm$j[index]] <- dtm$v[index]
}
return(m)
}
# main --------------------------------------------------------------------
n_sh = 0.01*n1
var_sh_all = c(1:10)/400
NN = length(var_sh_all)
mse4var = numeric(NN)
for(iii in 1:NN){
# split data --------------------------------------------------------------
print(iii)
var_sh = var_sh_all[iii]
pred_ori = numeric(nrow(cv_index))
for(ii in 1:cv_n){
split <- which(cv_index$index != ii)
train <- data_df[split,]
test <- data_df[-split,]
tidy_train <- train %>%
unnest_tokens(word, text)
tidy_test <- test %>%
unnest_tokens(word, text)
# not dict ----------------------------------------------------------------
data("stop_words")
## check stop words important or not
data_not <- data_df %>%
unnest_tokens(word, text)
var_not = data_frame(word = stop_words$word, var = 0)
count <- data_not %>%
count(stars)
for(i in 1:nrow(stop_words)){
var_not$var[i] = myvar(data_not, stop_words$word[i], count$n)
}
index_not = which(var_not$var>var_sh)
my_stop = stop_words[-index_not,]
my_stop2 <- my_stop
my_stop2$word = apply(my_stop, 1, add_not)
# delete stop word --------------------------------------------------------
tidy_train <- tidy_train %>%
anti_join(my_stop, by = "word") %>%
anti_join(my_stop2, by = "word")
# delete rear word --------------------------------------------------------
# tidy_train %>%
#   count(word, sort = T) %>%
#   filter(n > 1000) %>%
#   mutate(word = reorder(word, n))
major <- tidy_train %>%
count(word, sort = T) %>%
filter(n > n_sh)
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
# delete useless word -----------------------------------------------------
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
tidy_train_count <- tidy_train %>%
count(stars)
for(i in 1:nrow(word_var)){
word_var$var[i] = myvar(tidy_train, word_var$word[i], tidy_train_count$nn)
}
word_var <- word_var %>%
arrange(desc(var))
# for(i in 1:10){
#   this_word = word_var$word[i]
#   x <- tidy_test %>%
#     filter(word == this_word) %>%
#     count(stars) %>%
#     mutate(xx = n/sum(n))
#   ggplot(data = x) +
#     geom_bar(aes(x = stars, y = xx), stat = 'identity') +
#     ggtitle(this_word)
# }
k = sum(word_var$var>var_sh)
tidy_all <- data_df %>%
unnest_tokens(word, text)
tidy_all2 <- tidy_all %>%
filter(tidy_all$word %in% word_var$word[1:k]) %>%
mutate(count = 1)
xx <- tidy_all2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!c(1:nrow(data_df))   %in% xx$line)
star_mode = Mode(train$stars)
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
tidy_all3 <- full_join(tidy_all2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
# dataframe to matrix -----------------------------------------------------
n2 = length(unique(tidy_all3$word))
all_sp <- tidy_all3 %>%
cast_dtm(line, word, count)
# inspect(all_sp[20, 1:20])
all_matrix = dtm.to.Matrix(all_sp)
all_matrix2 = cbind(all_matrix, data_df$stars)
# fit model ---------------------------------------------------------------
split2 = split
train2 <- all_matrix2[split2,]
test2 <- all_matrix2[-split2,]
true_value = data_df$stars[-split2]
library(glmnet)
fit = glmnet(train2[,1:n2], train2[,n2+1])
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5)
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred_ori[-split] = pred
print(ii)
}
# mse ---------------------------------------------------------------------
pred_new = mymse2(my_sh, pred_ori)
mse = sum((pred_new - data_df$stars)^2)/length(data_df$stars)
mse4var[iii] = mse
}
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
# read data ---------------------------------------------------------------
data_ori = read_csv("../../data/li_first10000forR.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
n1 = length(data_df$line)
# parameter ---------------------------------------------------------------
my_sh = c(1.45, 2.92, 3.6, 4.15)
# my_sh = c(1.5, 2.5, 3.5 ,4.5)
# CV ----------------------------------------------------------------------
cv_n = 5
cv_df = tibble(index = c(1:cv_n))
set.seed(615)
cv_index = sample_n(cv_df, nrow(data_df), replace = T)
# variance ----------------------------------------------------------------
myvar = function(data, thisword, counts){
data_useful <- data %>%
filter(word == thisword) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
# mode fun ----------------------------------------------------------------
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# mse ---------------------------------------------------------------------
mymse2 = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
# add not -----------------------------------------------------------------
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
# dtm2matrix --------------------------------------------------------------
dtm.to.Matrix <- function(dtm)
{
m <- Matrix(0, nrow = dtm$nrow, ncol = dtm$ncol, sparse = TRUE)
for (index in 1:length(dtm$i)){
m[dtm$i[index], dtm$j[index]] <- dtm$v[index]
}
return(m)
}
# main --------------------------------------------------------------------
n_sh = 0.01*n1
var_sh_all = c(1:10)/400
NN = length(var_sh_all)
mse4var = numeric(NN)
for(iii in 1:NN){
# split data --------------------------------------------------------------
print(iii)
var_sh = var_sh_all[iii]
pred_ori = numeric(nrow(cv_index))
for(ii in 1:cv_n){
split <- which(cv_index$index != ii)
train <- data_df[split,]
test <- data_df[-split,]
tidy_train <- train %>%
unnest_tokens(word, text)
tidy_test <- test %>%
unnest_tokens(word, text)
# not dict ----------------------------------------------------------------
data("stop_words")
## check stop words important or not
data_not <- data_df %>%
unnest_tokens(word, text)
var_not = data_frame(word = stop_words$word, var = 0)
count <- data_not %>%
count(stars)
for(i in 1:nrow(stop_words)){
var_not$var[i] = myvar(data_not, stop_words$word[i], count$n)
}
index_not = which(var_not$var>var_sh)
my_stop = stop_words[-index_not,]
my_stop2 <- my_stop
my_stop2$word = apply(my_stop, 1, add_not)
# delete stop word --------------------------------------------------------
tidy_train <- tidy_train %>%
anti_join(my_stop, by = "word") %>%
anti_join(my_stop2, by = "word")
# delete rear word --------------------------------------------------------
# tidy_train %>%
#   count(word, sort = T) %>%
#   filter(n > 1000) %>%
#   mutate(word = reorder(word, n))
major <- tidy_train %>%
count(word, sort = T) %>%
filter(n > n_sh)
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
# delete useless word -----------------------------------------------------
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
tidy_train_count <- tidy_train %>%
count(stars)
for(i in 1:nrow(word_var)){
word_var$var[i] = myvar(tidy_train, word_var$word[i], tidy_train_count$nn)
}
word_var <- word_var %>%
arrange(desc(var))
# for(i in 1:10){
#   this_word = word_var$word[i]
#   x <- tidy_test %>%
#     filter(word == this_word) %>%
#     count(stars) %>%
#     mutate(xx = n/sum(n))
#   ggplot(data = x) +
#     geom_bar(aes(x = stars, y = xx), stat = 'identity') +
#     ggtitle(this_word)
# }
k = sum(word_var$var>var_sh)
tidy_all <- data_df %>%
unnest_tokens(word, text)
tidy_all2 <- tidy_all %>%
filter(tidy_all$word %in% word_var$word[1:k]) %>%
mutate(count = 1)
xx <- tidy_all2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!c(1:nrow(data_df))   %in% xx$line)
star_mode = Mode(train$stars)
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
tidy_all3 <- full_join(tidy_all2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
# dataframe to matrix -----------------------------------------------------
n2 = length(unique(tidy_all3$word))
all_sp <- tidy_all3 %>%
cast_dtm(line, word, count)
# inspect(all_sp[20, 1:20])
all_matrix = dtm.to.Matrix(all_sp)
all_matrix2 = cbind(all_matrix, data_df$stars)
# fit model ---------------------------------------------------------------
split2 = split
train2 <- all_matrix2[split2,]
test2 <- all_matrix2[-split2,]
true_value = data_df$stars[-split2]
library(glmnet)
fit = glmnet(train2[,1:n2], train2[,n2+1])
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5)
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred_ori[-split] = pred
print(ii)
}
# mse ---------------------------------------------------------------------
pred_new = mymse2(my_sh, pred_ori)
mse = sum((pred_new - data_df$stars)^2)/length(data_df$stars)
mse4var[iii] = mse
}
var_sh_all = c(10:1)/400
var_sh_all
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
# read data ---------------------------------------------------------------
data_ori = read_csv("../../data/li_first10000forR.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
n1 = length(data_df$line)
# parameter ---------------------------------------------------------------
my_sh = c(1.45, 2.92, 3.6, 4.15)
# my_sh = c(1.5, 2.5, 3.5 ,4.5)
# CV ----------------------------------------------------------------------
cv_n = 5
cv_df = tibble(index = c(1:cv_n))
set.seed(615)
cv_index = sample_n(cv_df, nrow(data_df), replace = T)
# variance ----------------------------------------------------------------
myvar = function(data, thisword, counts){
data_useful <- data %>%
filter(word == thisword) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
# mode fun ----------------------------------------------------------------
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# mse ---------------------------------------------------------------------
mymse2 = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
# add not -----------------------------------------------------------------
add_not = function(x){
return(paste("not", x[1], sep = ""))
}
# dtm2matrix --------------------------------------------------------------
dtm.to.Matrix <- function(dtm)
{
m <- Matrix(0, nrow = dtm$nrow, ncol = dtm$ncol, sparse = TRUE)
for (index in 1:length(dtm$i)){
m[dtm$i[index], dtm$j[index]] <- dtm$v[index]
}
return(m)
}
# main --------------------------------------------------------------------
n_sh = 0.01*n1
var_sh_all = c(10:1)/400
NN = length(var_sh_all)
mse4var = numeric(NN)
for(iii in 1:NN){
# split data --------------------------------------------------------------
print(iii)
var_sh = var_sh_all[iii]
pred_ori = numeric(nrow(cv_index))
for(ii in 1:cv_n){
split <- which(cv_index$index != ii)
train <- data_df[split,]
test <- data_df[-split,]
tidy_train <- train %>%
unnest_tokens(word, text)
tidy_test <- test %>%
unnest_tokens(word, text)
# not dict ----------------------------------------------------------------
data("stop_words")
## check stop words important or not
data_not <- data_df %>%
unnest_tokens(word, text)
var_not = data_frame(word = stop_words$word, var = 0)
count <- data_not %>%
count(stars)
for(i in 1:nrow(stop_words)){
var_not$var[i] = myvar(data_not, stop_words$word[i], count$n)
}
index_not = which(var_not$var>var_sh)
my_stop = stop_words[-index_not,]
my_stop2 <- my_stop
my_stop2$word = apply(my_stop, 1, add_not)
# delete stop word --------------------------------------------------------
tidy_train <- tidy_train %>%
anti_join(my_stop, by = "word") %>%
anti_join(my_stop2, by = "word")
# delete rear word --------------------------------------------------------
# tidy_train %>%
#   count(word, sort = T) %>%
#   filter(n > 1000) %>%
#   mutate(word = reorder(word, n))
major <- tidy_train %>%
count(word, sort = T) %>%
filter(n > n_sh)
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
# delete useless word -----------------------------------------------------
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
tidy_train_count <- tidy_train %>%
count(stars)
for(i in 1:nrow(word_var)){
word_var$var[i] = myvar(tidy_train, word_var$word[i], tidy_train_count$nn)
}
word_var <- word_var %>%
arrange(desc(var))
# for(i in 1:10){
#   this_word = word_var$word[i]
#   x <- tidy_test %>%
#     filter(word == this_word) %>%
#     count(stars) %>%
#     mutate(xx = n/sum(n))
#   ggplot(data = x) +
#     geom_bar(aes(x = stars, y = xx), stat = 'identity') +
#     ggtitle(this_word)
# }
k = sum(word_var$var>var_sh)
tidy_all <- data_df %>%
unnest_tokens(word, text)
tidy_all2 <- tidy_all %>%
filter(tidy_all$word %in% word_var$word[1:k]) %>%
mutate(count = 1)
xx <- tidy_all2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!c(1:nrow(data_df))   %in% xx$line)
star_mode = Mode(train$stars)
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
tidy_all3 <- full_join(tidy_all2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
# dataframe to matrix -----------------------------------------------------
n2 = length(unique(tidy_all3$word))
all_sp <- tidy_all3 %>%
cast_dtm(line, word, count)
# inspect(all_sp[20, 1:20])
all_matrix = dtm.to.Matrix(all_sp)
all_matrix2 = cbind(all_matrix, data_df$stars)
# fit model ---------------------------------------------------------------
split2 = split
train2 <- all_matrix2[split2,]
test2 <- all_matrix2[-split2,]
true_value = data_df$stars[-split2]
library(glmnet)
fit = glmnet(train2[,1:n2], train2[,n2+1])
cv <- cv.glmnet(train2[,1:n2], train2[,n2+1],nfolds=5)
pred <- predict(fit, test2[,1:n2],type="response", s=cv$lambda.min)
pred_ori[-split] = pred
print(ii)
}
# mse ---------------------------------------------------------------------
pred_new = mymse2(my_sh, pred_ori)
mse = sum((pred_new - data_df$stars)^2)/length(data_df$stars)
mse4var[iii] = mse
}
mse4var
var_sh_all
