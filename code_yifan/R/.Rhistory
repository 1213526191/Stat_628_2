filter(stars == n)
data_tidy2
data_tidy2 <- data_tidy %>%
filter(stars == 5) %>%
filter(word %in% word_var$word) %>%
group_by(word) %>%
summarise(nnn = n()) %>%
arrange(desc(nnn))
data_tidy2
filename = paste("../../data/dist", as.character(n), ".csv", sep = "")
filename
write_csv(data_tidy2, filename)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data_ori = read_csv("../../data/li_first100000forR.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
data_df
data_tidy <- data_df %>%
unnest_tokens(word, text)
data_tidy
n = 5
data_tidy
data_tidy2 <- data_tidy %>%
filter(stars == 5)  %>%
group_by(word) %>%
summarise(nnn = n()) %>%
arrange(desc(nnn))
data_tidy2
filename = paste("../../data/dist", as.character(n), "_ori.csv", sep = "")
filename
write_csv(data_tidy2, filename)
n = 1
data_tidy2 <- data_tidy %>%
filter(stars == 1)  %>%
group_by(word) %>%
summarise(nnn = n()) %>%
arrange(desc(nnn))
data_tidy2
filename = paste("../../data/dist", as.character(n), "_ori.csv", sep = "")
filename
write_csv(data_tidy2, filename)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
data_ori = read_csv("../../data/li_first100000forR.csv")
data_ori = read_csv("../../data/random100000.csv")
data_df = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
n1 = length(data_df$line)
n1
myexpect = function(words, data, counts){
data_useful <- data %>%
filter(word == words) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(sum(data_useful2$xx*c(1,2,3,4,5)))){
return(0)
}else{
return(sum(data_useful2$xx*c(1,2,3,4,5)))
}
}
n_sh = 0.01*nrow(data_df)
data_tidy <- data_df %>%
unnest_tokens(word, text)
major <- data_tidy %>%
count(word, sort = T) %>%
filter(n > n_sh)
major
data_tidy <- data_tidy %>%
inner_join(major, by = "word")
myvar = function(words, data, counts){
data_useful <- data %>%
filter(word == words) %>%
count(stars)
names(data_useful)[2] = "n"
my_star = tibble(stars = c(1:5), n = rep(0, 5))
data_useful2 <- rbind(data_useful, my_star) %>%
group_by(stars) %>%
summarise(n = max(n)) %>%
mutate(xx = n/counts) %>%
mutate(xx = xx/sum(xx))
if(is.na(var(data_useful2$xx))){
return(0)
}else{
return(var(data_useful2$xx))
}
}
data_tidy <- data_tidy %>%
inner_join(major, by = "word")
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
data_tidy_count <- data_tidy %>%
count(stars)
word_var$var <- apply(word_var[,1], 1, myvar,
data = data_tidy, counts = data_tidy_count$nn)
word_var[,1]
data_tidy
data_tidy <- data_df %>%
unnest_tokens(word, text)
major <- data_tidy %>%
count(word, sort = T) %>%
filter(n > n_sh)
data_tidy
major
data_tidy2 <- data_tidy %>%
inner_join(major, by = "word")
data_tidy2
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)))
data_tidy_count <- data_tidy %>%
count(stars)
data_tidy_count
data_tidy_count <- data_tidy2 %>%
count(stars)
data_tidy_count
word_var$var <- apply(word_var[,1], 1, myvar,
data = data_tidy2, counts = data_tidy_count$nn)
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)), expect = rep(0, nrow(major)))
word_var
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)), expect = rep(0, nrow(major)))
data_tidy_count <- data_tidy2 %>%
count(stars)
Sys.time()
t1 = Sys.time()
t2 = Sys.time()
print(t2-t1)
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)), expect = rep(0, nrow(major)))
data_tidy_count <- data_tidy2 %>%
count(stars)
t1 = Sys.time()
word_var$var <- apply(word_var[,1], 1, myvar,
data = data_tidy2, counts = data_tidy_count$nn)
word_var <- data_frame(word = major$word, var = rep(0, nrow(major)), expect = rep(0, nrow(major)))
data_tidy_count <- data_tidy2 %>%
count(stars)
t1 = Sys.time()
word_var$var <- apply(word_var[,1], 1, myvar,
data = data_tidy2, counts = data_tidy_count$nn)
t2 = Sys.time()
print(t2-t1)
word_var$expect <- apply(word_var[,1], 1, myexpect,
data = data_tidy2, counts = data_tidy_count$nn)
t3 = Sys.time()
print(t3-t2)
word_var
max(word_var$expect)
min(word_var$expect)
word_var <- word_var %>%
arrange(desc(var))
word_var
filename = paste("../../data/pos_neg.csv", sep = "")
filename
write_csv(word_var, filename)
library(tidyverse)
library(tidytext)
library(Matrix)
library(topicmodels)
library(glmnet)
#  read data --------------------------------------------------------------
data_ori = read_csv("../../data/random100000.csv")
test_ori = read_csv("/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/test.csv")
train = data_frame(line = 1:nrow(data_ori),
text = data_ori$text,
stars = data_ori$stars)
test = data_frame(line = 1:nrow(test_ori),
text = test_ori$text,
stars = 0)
n1 = length(data_df$line)
features = read_csv("../../data/pos_neg.csv")
NNN = sum(feature$var > 0.001)
NNN = sum(features$var > 0.001)
NNN
major = features$word[1:NNN]
my_sh = c(1.45, 2.92, 3.6, 4.15)
t1 = Sys.time()
tidy_train <- train %>%
unnest_tokens(word, text)
t2 = Sys.time()
print(t2-t1)
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
major
major <- features[1:NNN] %>%
select(word)
features
major <- features[1:NNN] %>%
select(word)
major
major <- features[1:NNN] %>%
select(word, expect)
major <- features[1:NNN]
major <- features[1:NNN,] %>%
select(word)
major
tidy_train <- tidy_train %>%
inner_join(major, by = "word")
tidy_train
tidy_train <- tidy_train %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
tidy_train
xx <- tidy_train %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!c(1:nrow(tidy_train))   %in% xx$line)
w
train_dtm <- tidy_train %>%
cast_dtm(line, word, count)
all_matrix <- tidy_all3 %>%
cast_sparse(line, word, count)
all_matrix <- tidy_train %>%
cast_sparse(line, word, count)
dim(
all_matrix)
dim(tidy_train)
dim(train)
xx <- tidy_train %>%
group_by(line) %>%
summarise(star = mean(stars))
tidy_train
w = which(!tidy_train$line   %in% xx$line)
w
w = which(!train$line   %in% xx$line)
w
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
train$stars[w]
star_mode = Mode(train$stars)
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
my_tidy
tidy_train
tidy_all3 <- full_join(tidy_train, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
all_matrix <- tidy_all3 %>%
cast_sparse(line, word, count)
all_matrix2 = cbind(all_matrix, train$stars)
n2 = length(unique(tidy_all3$word))
n2
tidy_train2 <- full_join(tidy_train, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
train_matrix <- tidy_train2 %>%
cast_sparse(line, word, count)
all_matrix2 = cbind(all_matrix, train$stars)
dim(all_matrix2)
n2 = dim(train_matrix)[1]
n2
n2 = dim(train_matrix)[2]
n2
all_matrix2 = cbind(all_matrix, train$stars)
fit = glmnet(train2[,1:n2], train2[,n2+1])
train_matrix2 = cbind(all_matrix, train$stars)
fit = glmnet(train_matrix2[,1:n2], train_matrix2[,n2+1])
cv <- cv.glmnet(train_matrix2[,1:n2], train_matrix2[,n2+1], nfolds=5)
t2 = Sys.time()
tidy_test <- test %>%
unnest_tokens(word, text)
t3 = Sys.time()
print(t3-t2)
tidy_test <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
tidy_test
xx <- tidy_test %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!test$line   %in% xx$line)
w
star_mode
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
my_tidy
tidy_train
t2 = Sys.time()
tidy_train2 <- full_join(tidy_train, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
t3 = Sys.time()
print(t3-t2)
tidy_test2 <- tidy_train2
tidy_test2
t2 = Sys.time()
test_matrix <- tidy_train2 %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
tidy_test2
test_matrix
pred <- predict(fit, test_matrix, type="response", s=cv$lambda.min)
length(pred)
dim(test_ori)
dim(test_matrix)
tidy_test2
length(unique(tidy_test2$line))
tidy_test
length(unique(tidy_test$line))
1016664      -1016507
length(w)
tidy_test2 <- full_join(tidy_test, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
t2 = Sys.time()
test_matrix <- tidy_test2 %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
pred <- predict(fit, test_matrix, type="response", s=cv$lambda.min)
mypred = function(sh, pred_ori){
pred_new = rep(0, length(pred_ori))
pred_new[which(pred_ori<sh[1])] = 1
pred_new[which(pred_ori>=sh[1] & pred_ori<sh[2])] = 2
pred_new[which(pred_ori>=sh[2] & pred_ori<sh[3])] = 3
pred_new[which(pred_ori>=sh[3] & pred_ori<sh[4])] = 4
pred_new[which(pred_ori>=sh[4])] = 5
return(pred_new)
}
length(pred)
pred_new = mymse2(my_sh, pred_ori)
pred_new = mypred(my_sh, pred_ori)
pred_new = mypred(my_sh, pred)
pred_new
result = tibble(line = c(1:length(pred_new)),
pred = pred_new)
?write_csv
write_csv(result, "~/Desktop")
write_csv(result, "/Users/Lyf/Desktop")
write_csv(result, "/Users/Lyf/Desktop/result.csv")
result = tibble(Id = c(1:length(pred_new)),
Prediction1 = pred_new)
write_csv(result, "/Users/Lyf/Desktop/result.csv")
pred
train
train %>%
group_by(stars) %>%
summarise(count = n())
prop <- train %>%
group_by(stars) %>%
summarise(count = n())
prop
total = sum(prop$count)
total
pred
names(pred)
pred[,2]
pred[1,]
?quantile
quantile(pred, prop$count[5]/total)
quantile(pred, prop$count/total)
probs = cumsum(prop$count)/total
probs
quantile(pred, probs[1:4])
my_sh = quantile(pred, probs[1:4])
pred_new = mypred(my_sh, pred)
result = tibble(Id = c(1:length(pred_new)),
Prediction1 = pred_new)
write_csv(result, "/Users/Lyf/Desktop/result.csv")
NNN = sum(features$var > 0.005)
major <- features[1:NNN,] %>%
select(word)
major
t1 = Sys.time()
tidy_train <- train %>%
unnest_tokens(word, text)
t2 = Sys.time()
print(t2-t1)
tidy_train2 <- tidy_train %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
xx <- tidy_train2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!train$line   %in% xx$line)
w
Mode(c(1,2,3))
star_mode = Mode(train2$stars)
Q
Q
train2$stars
star_mode = Mode(train$stars)
w
tidy_train2$stars[which(tidy_train2$line == w)]
tidy_train2$stars[which(tidy_train2$line %in% w)]
w
tidy_train2
features = read_csv("../../data/pos_neg.csv")
NNN = sum(features$var > 0.005)
major <- features[1:NNN,] %>%
select(word)
my_sh = c(1.45, 2.92, 3.6, 4.15)
t1 = Sys.time()
tidy_train <- train %>%
unnest_tokens(word, text)
t2 = Sys.time()
print(t2-t1)
tidy_train2 <- tidy_train %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
xx <- tidy_train2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!train$line   %in% xx$line)
star_mode = Mode(train$stars)
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
my_tidy
tidy_train2 <- full_join(tidy_train, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
tidy_train2 <- full_join(tidy_train2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
tidy_train3 = tidy_train2
train_matrix <- tidy_train3 %>%
cast_sparse(line, word, count)
n2 = dim(train_matrix)[2]
train_matrix2 = cbind(all_matrix, train$stars)
fit = glmnet(train_matrix2[,1:n2], train_matrix2[,n2+1])
cv <- cv.glmnet(train_matrix2[,1:n2], train_matrix2[,n2+1], nfolds=5)
time()
tidy_test <- test %>%
unnest_tokens(word, text)
t3 = Sys.time()
print(t3-t2)
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
xx <- tidy_test2 %>%
group_by(line) %>%
summarise(star = mean(stars))
w = which(!test$line   %in% xx$line)
w
2000/100000
my_tidy = tibble(
line = w,
stars = rep(star_mode, length(w)),
word = rep("myWord", length(w)),
count = rep(1, length(w))
)
my_tidy
t2 = Sys.time()
tidy_test2 <- full_join(tidy_test, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
t3 = Sys.time()
print(t3-t2)
tidy_test
tidy_test2
t2 = Sys.time()
tidy_test2 <- full_join(tidy_test2, my_tidy, by = c("line", "stars", "word", "count")) %>%
arrange(line)
t3 = Sys.time()
print(t3-t2)
tidy_test3 = tidy_test2
tidy_test3
tidy_test
tidy_test3
tidy_test2
my_tidy
tidy_test
tidy_test2 <- tidy_test %>%
inner_join(major, by = "word") %>%
mutate(count = 1)
tidy_test2
t2 = Sys.time()
test_matrix <- tidy_test3 %>%
cast_sparse(line, word, count)
t3 = Sys.time()
print(t3-t2)
pred <- predict(fit, test_matrix, type="response", s=cv$lambda.min)
prop <- train %>%
group_by(stars) %>%
summarise(count = n())
total = sum(prop$count)
probs = cumsum(prop$count)/total
quantile(pred, probs[1:4])
pred
min(pred)
max(pred)
fit
