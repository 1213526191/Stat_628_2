{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/data/train_data.csv'\n",
    "reviews = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = reviews[0:N].copy()\n",
    "yelp_ori = yelp.copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加上长度变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.loc[:, 'text length'] = yelp['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改缩写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    sentence = yelp['text'][i]\n",
    "    sentence2 = re.sub('n\\'t', ' not', sentence)\n",
    "    sentence3 = re.sub('\\'s', ' is', sentence2)\n",
    "    sentence4 = re.sub('\\'ve', ' have', sentence3)\n",
    "    sentence5 = re.sub('\\'d', ' would', sentence4)\n",
    "    sentence6 = re.sub('\\'m', ' am', sentence5)\n",
    "    sentence7 = re.sub('Ive', 'I have', sentence6)\n",
    "    yelp.loc[i, 'text'] = sentence6\n",
    "#     if(i%100 == 0):\n",
    "#         print(i/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete unEnglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "index = []\n",
    "for i in range(N):\n",
    "    sentence = yelp['text'][i]\n",
    "    sentence4 = re.sub('[^a-zA-Z]',' ', sentence)\n",
    "    words = sentence4.split()\n",
    "    n = 0\n",
    "    count = 0\n",
    "    for j in range(len(words)):\n",
    "        word = words[j]\n",
    "        if d.check(word):\n",
    "            count += 1\n",
    "#         else:\n",
    "#             print(word)\n",
    "        n += 1\n",
    "    if(n == 0):\n",
    "#         print(i)\n",
    "        index.append(i)\n",
    "    else:\n",
    "        if(count/n < 0.8):\n",
    "            index.append(i)       \n",
    "# time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp2 = yelp.drop(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_total = ''\n",
    "for i in range(N):\n",
    "    reviews_total = reviews_total+\" \"+yelp.loc[i, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_total\n",
    "positive_words = [\"nice\",\"prime\",\"great\",\"awesome\",\"yummy\",\"friendly\",\"delicious\",\n",
    "                  \"love\",\"spicy\",\"good\",\"favorite\",\"well\",\"clean\",\"enjoy\"]\n",
    "negetive_words = [\"suck\",\"terrible\",\"amazing\",\"messy\",\"worse\",\"hit\",\"miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw this restaurant on a whim when I was looking for a good indian food place to try and decided that this was the one. We opted for delivery because why not.\n",
      "\n",
      "I usually judge the place based on my all time favourite Butter chicken and when I got it for sure this place has it down! It surpassed the other ones I tried and for sure this is where am getting it from now on.\n",
      "\n",
      "Aside from that dish, we also got the chicken tikka masala and the garlic naan bread. The masala was alright, I tasted a better one elsewhere so this one wasn't really my favourite from them. And the garlic naan was yummy. Really generous with the garlic for sure. \n",
      "\n",
      "And I also got a Mango lassi, I didnt like their version that much so I think I'll skip on this one next time.\n",
      "\n",
      "Anyway, I have yet to try their other dishes in the future so for now am just giving them three stars. And also the other reason for the rating was because our food arrived late. Am glad I waited a little bit more because I was close to complaining. But other than that, food is decent and I would order from them again.\n"
     ]
    }
   ],
   "source": [
    "print(reviews['text'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_not(sentence):\n",
    "    words = sentence.split().copy()\n",
    "    not_index = 0\n",
    "    for index, word in enumerate(words):\n",
    "        if(not_index != 0):\n",
    "            words[index] = 'not_' + words[index]\n",
    "        if(re.match('.*[,.?!\\'\\\"]$', word)):\n",
    "            not_index = 0\n",
    "        if(word == 'not'):\n",
    "            not_index = 1\n",
    "    #         print(index)\n",
    "    sentence = \" \".join(words)\n",
    "    return(sentence)\n",
    "for i in range(N):\n",
    "    sentence = yelp.loc[i, 'text']\n",
    "    sentence2 = add_not(sentence)\n",
    "    yelp.loc[i, 'text'] = sentence2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 停词，标点加去时态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "stem = PorterStemmer()\n",
    "\n",
    "def noise_remove(review):\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    review = review.lower().split()\n",
    "    useful_review = [w for w in review if not w in stops]  \n",
    "    return \" \".join([stem.stem(w) for w in useful_review])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp3 = yelp2.copy()\n",
    "for i in range(yelp3.shape[0]):\n",
    "    yelp3.iloc[i, 2] = noise_remove(yelp2.iloc[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp3.to_csv(\"first10000.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
