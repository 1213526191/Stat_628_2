{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/Lyf/OneDrive/study/WISC/2017_spring/Stat_628/hw2/data/train_data.csv'\n",
    "reviews = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = reviews[0:N].copy()\n",
    "yelp_ori = yelp.copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 加上长度变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.loc[:, 'text length'] = yelp['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 改缩写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortcut_dir = {'n\\'t': ' not', '\\'s': ' is', '\\'ve': ' have', '\\'d': ' would', '\\'m': ' am', 'Ive': 'I have'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998816728591919"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "def shortcut_remove(review):\n",
    "    for i in shortcut_dir:\n",
    "        review = re.sub(i, shortcut_dir[i], review)\n",
    "    return review\n",
    "yelp2 = yelp.copy()\n",
    "yelp2['text'] = yelp2['text'].apply(shortcut_remove)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Delete unEnglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.9606430530548"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_english(word):\n",
    "    return(d.check(word))\n",
    "    \n",
    "def unEnglish_remove(review):\n",
    "    review = re.sub('[^a-zA-Z]',' ', review)\n",
    "    words = pd.Series(review.split())\n",
    "    index = words.apply(check_english)\n",
    "    if(len(index)==0):\n",
    "        return True\n",
    "    else:\n",
    "        return(sum(index)/len(index)>0.8)\n",
    "t1 = time.time()\n",
    "index = yelp2['text'].apply(unEnglish_remove)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp3 = yelp2[index].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-aaa747cf4801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreviews_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreviews_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_total\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0myelp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reviews_total = ''\n",
    "for i in range(N):\n",
    "    reviews_total = reviews_total+\" \"+yelp.loc[i, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_total\n",
    "positive_words = [\"nice\",\"prime\",\"great\",\"awesome\",\"yummy\",\"friendly\",\"delicious\",\n",
    "                  \"love\",\"spicy\",\"good\",\"favorite\",\"well\",\"clean\",\"enjoy\"]\n",
    "negetive_words = [\"suck\",\"terrible\",\"amazing\",\"messy\",\"worse\",\"hit\",\"miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw this restaurant on a whim when I was looking for a good indian food place to try and decided that this was the one. We opted for delivery because why not.\n",
      "\n",
      "I usually judge the place based on my all time favourite Butter chicken and when I got it for sure this place has it down! It surpassed the other ones I tried and for sure this is where am getting it from now on.\n",
      "\n",
      "Aside from that dish, we also got the chicken tikka masala and the garlic naan bread. The masala was alright, I tasted a better one elsewhere so this one wasn't really my favourite from them. And the garlic naan was yummy. Really generous with the garlic for sure. \n",
      "\n",
      "And I also got a Mango lassi, I didnt like their version that much so I think I'll skip on this one next time.\n",
      "\n",
      "Anyway, I have yet to try their other dishes in the future so for now am just giving them three stars. And also the other reason for the rating was because our food arrived late. Am glad I waited a little bit more because I was close to complaining. But other than that, food is decent and I would order from them again.\n"
     ]
    }
   ],
   "source": [
    "print(reviews['text'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 去标点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_remove(review):\n",
    "    review = review.lower()\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    return review\n",
    "t1 = time.time()\n",
    "yelp4 = yelp3.copy()\n",
    "yelp4['text'] = yelp4['text'].apply(punctuation_remove)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_chen = \"../data/chen_first\"+str(N)+\".csv\"\n",
    "yelp4.to_csv(filename_chen, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 去时态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209.00807809829712"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "stem = PorterStemmer()\n",
    "def tense_remove(review):\n",
    "    review = review.split()\n",
    "    return \" \".join([stem.stem(w) for w in review])\n",
    "t1 = time.time()\n",
    "yelp5 = yelp4.copy()\n",
    "yelp5['text'] = yelp5['text'].apply(tense_remove)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Add not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.80996322631836"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_not(sentence):\n",
    "    words = sentence.split().copy()\n",
    "    not_index = 0\n",
    "    for index, word in enumerate(words):\n",
    "        if(not_index != 0):\n",
    "            words[index] = 'not_' + words[index]\n",
    "        if(re.match('.*[,.?!\\'\\\"]$', word)):\n",
    "            not_index = 0\n",
    "        if(word == 'not'):\n",
    "            not_index = 1\n",
    "    #         print(index)\n",
    "    sentence = \" \".join(words)\n",
    "    return(sentence)\n",
    "t1 = time.time()\n",
    "yelp6 = yelp5.copy()\n",
    "yelp6['text'] = yelp6['text'].apply(add_not)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 去停词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.492175817489624"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def noise_remove(review):\n",
    "    review = review.split()\n",
    "    useful_review = [w for w in review if not w in stops]  \n",
    "    return \" \".join([w for w in useful_review])\n",
    "t1 = time.time()\n",
    "yelp7 = yelp6.copy()\n",
    "yelp7['text'] = yelp7['text'].apply(noise_remove)\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_li = \"../data/li_first\"+str(N)+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp7.to_csv(filename_li, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first10000.csv'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'long stori short bunch rude heartless ignor asshol run place compass peopl especi peopl feel belong suitabl shitti establish mother endur extrem humili situat bonjour brioch went saturday wait min cane nowher sit wait friend number peopl wait seat ask would get seat friend arriv would like coffe wait basic told friend tough shit seat wait ask well guest cancel last minut would like eat alon go serv even sit someth alon start tell get excus time could get tabl friend arriv ask manag friend arriv time explain manag wait cane given tabl peopl seat even wait other felt demean appreci servic would take busi somewher els instead manag make arrang eas situat told mother leav never life mother call cri phone humili embarrass felt absolut disgust'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp4['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first10000.csv'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
